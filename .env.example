# ==================== LLM Configuration ====================
# Multi-LLM Plug-and-Play Support
# Configura el proveedor que desees usar (openai, deepseek, groq, ollama, etc.)

# Provider Selection (openai, deepseek, groq, ollama, gemini, anthropic)
LLM_PROVIDER=openai

# === OpenAI (Default) ===
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=2000
# OPENAI_BASE_URL=https://api.openai.com/v1  # Opcional, solo si usas proxy

# === DeepSeek (Alternativa económica) ===
# LLM_PROVIDER=deepseek
# OPENAI_API_KEY=sk-your-deepseek-key
# OPENAI_MODEL=deepseek-chat
# OPENAI_BASE_URL=https://api.deepseek.com/v1
# DEEPSEEK_API_KEY=sk-your-deepseek-key  # Para ensemble

# === Groq (Ultra rápido - Mixtral/Llama) ===
# LLM_PROVIDER=groq
# OPENAI_API_KEY=gsk-your-groq-key
# OPENAI_MODEL=mixtral-8x7b-32768
# OPENAI_BASE_URL=https://api.groq.com/openai/v1
# GROQ_API_KEY=gsk-your-groq-key  # Para ensemble

# === Ollama (Local - Sin API key) ===
# LLM_PROVIDER=ollama
# OPENAI_API_KEY=ollama
# OPENAI_MODEL=llama3.1
# OPENAI_BASE_URL=http://localhost:11434/v1

# ==================== Database Configuration ====================
VECTORDB_PATH=./storage/vectordb
SQLITE_DB_PATH=./storage/sqlite/faq.db

# Notification Configuration (Pushover)
PUSHOVER_TOKEN=your_pushover_token_here
PUSHOVER_USER=your_pushover_user_key_here

# API Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=false

# RAG Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K_RESULTS=5
SIMILARITY_THRESHOLD=0.7

# Gradio UI Configuration
GRADIO_PORT=7860
GRADIO_SHARE=false
# ğŸ¨ Interfaz Gradio Multi-LLM - GuÃ­a de Uso

## ğŸŒŸ Nueva Funcionalidad

Se agregÃ³ una **interfaz web mejorada** que permite:

- âœ… **Cambiar de proveedor LLM en tiempo real** (OpenAI â†” DeepSeek â†” Groq â†” Ollama)
- âœ… **Selector dinÃ¡mico de modelos** segÃºn proveedor
- âœ… **Ver estado de proveedores** configurados
- âœ… **Comparar respuestas** sin reiniciar la aplicaciÃ³n
- âœ… **Metadata visual** mostrando proveedor/modelo usado

---

## ğŸš€ CÃ³mo Ejecutar

### OpciÃ³n 1: Interfaz Multi-LLM (Recomendada)

```bash
# Activar entorno virtual
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# Lanzar interfaz con selector de proveedores
python run_multi_llm_ui.py
```

### OpciÃ³n 2: Interfaz Original

```bash
# UI tradicional (sin selector)
python run_ui_only.py
```

---

## ğŸ¯ Uso de la Interfaz

### 1ï¸âƒ£ **Seleccionar Proveedor**

En la parte superior verÃ¡s:

```
âš™ï¸ ConfiguraciÃ³n de Proveedor LLM
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Proveedor  â”‚      Modelo      â”‚  Aplicar â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pasos:**

1. Selecciona un proveedor en el dropdown (ej: "DeepSeek")
2. El dropdown de modelos se actualiza automÃ¡ticamente
3. Selecciona un modelo (ej: "deepseek-chat")
4. Haz clic en "ğŸ”„ Aplicar"
5. VerÃ¡s confirmaciÃ³n: `âœ… Proveedor cambiado a ğŸ§  DeepSeek`

### 2ï¸âƒ£ **Hacer Preguntas**

```
ğŸ’¬ Chat
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ConversaciÃ³n                         â”‚
â”‚                                      â”‚
â”‚ Usuario: Â¿CuÃ¡les son mis proyectos? â”‚
â”‚ Agente: [Respuesta...]              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Escribe tu pregunta aquÃ­...
[ğŸ“¤ Enviar] [ğŸ—‘ï¸ Limpiar]
â˜‘ Evaluar respuesta
```

### 3ï¸âƒ£ **Ver InformaciÃ³n de Respuesta**

En el panel derecho verÃ¡s:

```
ğŸ“Š InformaciÃ³n
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Proveedor: ğŸ§  DeepSeek
Modelo: deepseek-chat
Fuentes: rag, faq
Tiempo: 1.23s
Contexto: 456 chars
EvaluaciÃ³n: 8.5/10
```

### 4ï¸âƒ£ **Comparar Proveedores**

**Ejemplo: Comparar OpenAI vs DeepSeek**

1. **Con OpenAI:**

   - Selecciona "OpenAI" â†’ "gpt-3.5-turbo"
   - Pregunta: "Â¿QuÃ© tecnologÃ­as domino?"
   - Observa: Tiempo de respuesta, calidad

2. **Cambiar a DeepSeek:**

   - Selecciona "DeepSeek" â†’ "deepseek-chat"
   - Haz clic en "ğŸ”„ Aplicar"
   - Pregunta lo mismo
   - Compara: Velocidad, costo, calidad

3. **Probar con Groq:**
   - Selecciona "Groq" â†’ "mixtral-8x7b-32768"
   - Aplica
   - Misma pregunta
   - Nota: âš¡ Ultra rÃ¡pido

---

## ğŸ“Š Estado de Proveedores

Haz clic en **"Ver Estado de Proveedores"** para ver:

```
ğŸ“Š Estado de Proveedores

âœ… ğŸ¤– OpenAI - 4 modelos disponibles
âœ… ğŸ§  DeepSeek - 2 modelos disponibles
âŒ âš¡ Groq - Requiere GROQ_API_KEY en .env
âœ… ğŸ¦™ Ollama - 4 modelos disponibles
```

---

## âš™ï¸ ConfiguraciÃ³n

### Variables de Entorno Necesarias

Para que todos los proveedores estÃ©n disponibles:

```env
# OpenAI (siempre funciona con OPENAI_API_KEY)
OPENAI_API_KEY=sk-proj-xxxxx

# DeepSeek (opcional)
DEEPSEEK_API_KEY=sk-xxxxx

# Groq (opcional)
GROQ_API_KEY=gsk-xxxxx

# Ollama no requiere API key, solo que estÃ© corriendo
```

### Probar con un Solo Proveedor

Si solo tienes OpenAI configurado:

1. La UI mostrarÃ¡ solo OpenAI disponible âœ…
2. DeepSeek, Groq aparecerÃ¡n como âŒ
3. Puedes usar OpenAI normalmente
4. Cuando configures otros, estarÃ¡n disponibles automÃ¡ticamente

---

## ğŸ¬ Ejemplos de Casos de Uso

### Caso 1: Desarrollo (sin costo)

```
1. Seleccionar: Ollama â†’ llama3.1
2. Desarrollar y probar localmente
3. Sin gastar en API calls
```

### Caso 2: ProducciÃ³n econÃ³mica

```
1. Seleccionar: DeepSeek â†’ deepseek-chat
2. 99% mÃ¡s barato que GPT-4
3. Calidad muy buena
```

### Caso 3: MÃ¡xima velocidad

```
1. Seleccionar: Groq â†’ mixtral-8x7b-32768
2. Respuestas en <1 segundo
3. Gratis (con lÃ­mites)
```

### Caso 4: MÃ¡xima calidad

```
1. Seleccionar: OpenAI â†’ gpt-4
2. Mejor calidad de respuestas
3. Mayor costo
```

---

## ğŸ’¡ Tips

### Tip 1: ComparaciÃ³n A/B

```
1. Pregunta con GPT-4
2. Guarda la respuesta
3. Cambia a DeepSeek
4. Misma pregunta
5. Compara calidad/costo
```

### Tip 2: Fallback automÃ¡tico

```
1. Si un proveedor falla
2. Cambiar rÃ¡pidamente a otro
3. Sin reiniciar la aplicaciÃ³n
```

### Tip 3: Testing de modelos

```
1. Probar pregunta compleja
2. Con cada proveedor
3. Documentar resultados
4. Elegir el Ã³ptimo por uso
```

---

## ğŸ› Troubleshooting

### Problema: "âŒ Proveedor no configurado"

**SoluciÃ³n:**

```bash
# Ver quÃ© falta
python quickstart_multi_llm.py

# AÃ±adir API key en .env
DEEPSEEK_API_KEY=sk-xxxxx

# Reiniciar UI (o refrescar pÃ¡gina)
```

### Problema: Ollama no disponible

**SoluciÃ³n:**

```bash
# Iniciar Ollama
ollama serve

# Verificar
curl http://localhost:11434/api/tags

# Descargar modelo si es necesario
ollama pull llama3.1
```

### Problema: Cambio no se aplica

**SoluciÃ³n:**

1. Verifica que hiciste clic en "ğŸ”„ Aplicar"
2. Mira el mensaje de estado
3. Si hay error, revisa los logs en la terminal

---

## ğŸ“ˆ Beneficios de la UI

| Funcionalidad             | Beneficio                       |
| ------------------------- | ------------------------------- |
| **Cambio en tiempo real** | No reiniciar aplicaciÃ³n         |
| **ComparaciÃ³n A/B**       | Elegir mejor proveedor por caso |
| **Estado visual**         | Ver quÃ© estÃ¡ configurado        |
| **Metadata detallada**    | Debugging y optimizaciÃ³n        |
| **EvaluaciÃ³n opcional**   | MÃ©tricas de calidad             |

---

## ğŸ¯ PrÃ³ximos Pasos

1. **Prueba la interfaz:**

   ```bash
   python run_multi_llm_ui.py
   ```

2. **Configura mÃ¡s proveedores:**

   - AÃ±ade GROQ_API_KEY para ultra velocidad
   - AÃ±ade DEEPSEEK_API_KEY para bajo costo

3. **Compara resultados:**

   - Misma pregunta, diferentes proveedores
   - Documenta cuÃ¡l funciona mejor para tu caso

4. **Optimiza costos:**
   - Usa DeepSeek/Groq para preguntas simples
   - Reserva GPT-4 para preguntas complejas

---

## ğŸ“š Recursos Adicionales

- **GuÃ­a completa**: `docs/MULTI_LLM_GUIDE.md`
- **Demo CLI**: `examples/multi_llm_demo.py`
- **Quickstart**: `quickstart_multi_llm.py`
- **Resumen tÃ©cnico**: `IMPLEMENTATION_MULTI_LLM.md`

---

**ğŸ‰ Â¡Disfruta la flexibilidad de Multi-LLM!**
